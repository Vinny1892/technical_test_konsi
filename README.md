# API Scrap Beneficio


## Descri√ß√£o

O projeto esta separado na api rest e no etl feito para fazer scarp dos dados


## üíª Pr√©-requisitos

  

Antes de come√ßar, verifique se voc√™ atendeu aos seguintes requisitos:

* docker `^20.10.8`
* docker-compose `^2.19.1`


  

<br>

  

## üöÄ Instala√ß√£o
 o arquivo de .env √© utilizado para popular as variaveis necessarias para aplica√ß√£o se conectar com servi√ßos externos necessarios e funcionar corretamente. Para utiliza√ß√£o com o docker-compose-common n√£o √© necessario nenhuma mudan√ßa nos valores presente .env.example.
   Caso seja a primeira vez subindo o servi√ßo entrar na pasta da api ou do crawler_benefit e rodar os seguintes comandos.
     - make init
     - make create-elasticsearch-index
 No caso do ocorrer erro no ultimo comando aguarde alguns segundos e ent√£o execute novamente, esse erro aconte√ße porque pode ser que o elasticsearch ainda n√£o esteja iniciado totalmente.  
<br>

  

  

### Clone este reposit√≥rio usando ssh ou https

````

$ git clone git@github.com:Vinny1892/technical_test_konsi.git

````

#### Acesse a pasta do projeto no terminal/cmd

```

$ cd technical_test_konsi

```

  

<br>

  

### Para fazer build da imagem docker:

 acessar a pasta  technical_test_konsi/api/ ou a pasta technical_test_konsi/etl/crawler_benefit. podendo usar o build para produc√£o e desenvolvimento

```docker

$ docker build -f docker/development/dockerfile -t user/name-image

```

Aonde:

* User = Usuario dockerhub

* Name-image = Nome da imagem

  
  

<!-- Para instalar o projeto , siga estas etapas: -->

  
<br>

  

#### Executa a aplica√ß√£o em modo desenvolvimento

  

```

$ docker-compose up -d

```


## Execu√ß√£o dos testes e fixtures

Para execu√ß√£o dos testes e de outros comandos de forma simplificada no perojeto foi criado um `Makefile`, para rodar os testes s√≥ precisa rodar
```
make up-silent
make test
```



## üõ† Tecnologias

  

As seguintes servi√ßos foram usados na constru√ß√£o do projeto:

  
- [Selenium](https://www.selenium.dev/)

- [RabbitMQ](https://www.rabbitmq.com/)

- [elasticsearch](https://www.elastic.co/pt/)

- [redis](https://redis.io/)



## Endpoints

 Ap√≥s instalado a aplica√ß√£o pode-se acessar os recursos listados abaixo
   - buscar um beneficio que ja foi feito webscrap
   - fazer webscrap de um beneficio

### fazer webscrap de um beneficio

POST  http://localhost:32568/benefit com o body abaixo

```json

{
	"cpf": "<cpf para buscar o numero do beneficio>",
	"login": "usuario na plataforma",
	"password": "senha na plataforma"
}
````
tamb√©m pode utilizar com o curl dessa forma.
```bash

curl -X POST -H "Content-Type: application/json" -d '{
	"cpf": "<cpf para buscar o numero do beneficio>",
	"login": "usuario na plataforma",
	"password": "senha na plataforma"
}' http://localhost:32568/benefit


`````
###  buscar um beneficio que ja foi feito webscrap

 Utilizar um get com o cpf que tem o numero atrelado ao beneficio

GET  http://localhost:32568/benefit/cpf 
tamb√©m pode utilizar com o curl dessa forma.
```bash

curl -X GET -H "Content-Type: application/json" http://localhost:32568/benefit/<cpf>

`````

# Arquitetura
   - [ETL CRAWLER BENEFICIO](./etl/crawler_benefit/README.md)
   - [API](./api/README.md)